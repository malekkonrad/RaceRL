# ğŸï¸ RaceRL
Autonomous racing with reinforcement learning.

## Opis projektu

Projekt zakÅ‚ada stworzenie trÃ³jwymiarowej symulacji wyÅ›cigÃ³w samochodowych, w ktÃ³rej uczestniczÄ… autonomiczni kierowcy sterowani przez algorytmy uczenia ze wzmocnieniem (Reinforcement Learning). Åšrodowisko bÄ™dzie obejmowaÄ‡ rÃ³Å¼norodne tory wyÅ›cigowe oraz realistycznÄ… fizykÄ™ jazdy, uwzglÄ™dniajÄ…cÄ… takie zjawiska jak opory powietrza, drafting, downforce czy przyczepnoÅ›Ä‡ opon.

KaÅ¼dy pojazd w symulacji bÄ™dzie kontrolowany przez agenta AI, ktÃ³ry na podstawie obserwacji Å›rodowiska - takich jak wektor prÄ™dkoÅ›ci i kierunku samochodu, informacje o nadchodzÄ…cych zakrÄ™tach (odlegÅ‚oÅ›Ä‡ i typ), stopieÅ„ poÅ›lizgu kÃ³Å‚ oraz dane z zestawu promieni (raycastÃ³w) mierzÄ…cych odlegÅ‚oÅ›Ä‡ od przeszkÃ³d - podejmie decyzje dotyczÄ…ce sterowania.

Agent bÄ™dzie dysponowaÅ‚ trzema ciÄ…gÅ‚ymi parametrami sterujÄ…cymi: skrÄ™tem kÃ³Å‚ (zakres od -1 do 1), pedaÅ‚em gazu i pedaÅ‚em hamulca. Celem kaÅ¼dego agenta bÄ™dzie ukoÅ„czenie wyÅ›cigu w jak najkrÃ³tszym czasie, rywalizujÄ…c z innymi uczestnikami o zwyciÄ™stwo.

System ma umoÅ¼liwiaÄ‡ interakcje miÄ™dzy agentami, w tym zderzenia, wyprzedzanie i wykorzystanie efektÃ³w aerodynamicznych przeciwnikÃ³w. ZakÅ‚ada siÄ™, Å¼e w trakcie treningu agenci nauczÄ… siÄ™ zÅ‚oÅ¼onych strategii wyÅ›cigowych, takich jak drafting czy tandem racing, odzwierciedlajÄ…cych realistyczne zachowania kierowcÃ³w w profesjonalnych wyÅ›cigach.



## Cel projektu

Stworzenie inteligentnego systemu wyÅ›cigowego z wykorzystaniem reinforcement learning, w ktÃ³rym agenci AI najpierw uczÄ… siÄ™ podstaw jazdy, a nastÄ™pnie rozwijajÄ… umiejÄ™tnoÅ›ci kompetytywnego Å›cigania siÄ™ ze sobÄ… w czasie rzeczywistym. Projekt zakÅ‚ada progresywne nauczanie agentÃ³w - od podstawowych umiejÄ™tnoÅ›ci sterowania pojazdem, przez optymalizacjÄ™ tras, aÅ¼ po zaawansowane strategie wyÅ›cigowe i interakcje miÄ™dzy konkurujÄ…cymi agentami.



## Zakres projektu

#### Åšrodowisko symulacyjne
- Budowa kompletnego Å›rodowiska wyÅ›cigowego 3D w Unity (tor, checkpointy, system detekcji kolizji)
- Integracja Unity ML-Agents Toolkit
- Implementacja fizyki pojazdÃ³w (realistyczna jazda, przyczepnoÅ›Ä‡, zarzÄ…dzanie prÄ™dkoÅ›ciÄ…)
- System wizualizacji i monitorowania treningu

#### Modelowanie agentÃ³w
- **Etap 1: Podstawowa jazda** - agent uczy siÄ™ trzymaÄ‡ tor, nie wypadaÄ‡, kontrolowaÄ‡ prÄ™dkoÅ›Ä‡
- **Etap 2: Optymalizacja** - minimalizacja czasu okrÄ…Å¼enia, optymalne tory przejazdu zakrÄ™tÃ³w
- **Etap 3: WyÅ›cigi kompetytywne** - strategie wyprzedzania, obrona pozycji, Å›wiadomoÅ›Ä‡ przeciwnikÃ³w

#### Systemy uczÄ…ce
- Projektowanie przestrzeni obserwacji (raycasty, prÄ™dkoÅ›Ä‡, pozycja na torze, pozycje przeciwnikÃ³w)
- Definiowanie przestrzeni akcji (sterowanie, przyspieszenie, hamowanie)
- Funkcje nagrÃ³d dostosowane do kaÅ¼dego etapu uczenia
- Curriculum learning - stopniowe zwiÄ™kszanie trudnoÅ›ci

#### Metryki i analiza
- Podstawowe: Å›redni czas okrÄ…Å¼enia, procent ukoÅ„czonych okrÄ…Å¼eÅ„ bez kolizji, liczba kolizji na wyÅ›cig
- Zaawansowane: liczba wyprzedzeÅ„, obronione pozycje, analiza linii przejazdu, stabilnoÅ›Ä‡ prÄ™dkoÅ›ci i sterowania (jako odchylenie standardowe prÄ™dkoÅ›ci i kÄ…ta skrÄ™tu)



#### Wizualizacja i prezentacja
- System kamer do obserwacji wyÅ›cigu
- UI z informacjami o wyÅ›cigu (pozycje, czasy okrÄ…Å¼eÅ„)
- NarzÄ™dzia do analizy postÄ™pÃ³w treningu (wykresy, statystyki)
- Demo finaÅ‚owe z wyÅ›cigiem na Å¼ywo




## Harmonogram

###  TydzieÅ„ 1 (13-17.10): Inicjalizacja projektu
- [ ] Instalacja i konfiguracja Å›rodowiska Unity oraz ML-Agents Toolkit
- [ ] Zapoznanie siÄ™ z Å›rodowiskiem Unity oraz przeglÄ…d dokumentacji ML-Agents
- [ ] Stworzenie podstawowego projektu Unity z prostym torem

### TydzieÅ„ 2 (20-24.10): Podstawowe Å›rodowisko treningowe
- [ ] Modelowanie prostego toru wyÅ›cigowego (prosta + kilka zakrÄ™tÃ³w)
- [ ] Implementacja systemu checkpointÃ³w
- [ ] Podstawowa kamera i oÅ›wietlenie
- [ ] Import lub stworzenie prostego modelu pojazdu 3D

### TydzieÅ„ 3 (27-31.10): Fizyka pojazdu
- [ ] Konfiguracja Rigidbody i colliderÃ³w
- [ ] Implementacja systemu sterowania (WheelColliders)
- [ ] Podstawowa fizyka: przyspieszanie, hamowanie, skrÄ™canie
- [ ] Testowanie manualnego sterowania (klawiatura)

### TydzieÅ„ 4 (3-7.11): Integracja ML-Agents
- [ ] Integracja ML-Agents Toolkit z projektem
- [ ] Konfiguracja agentÃ³w i Å›rodowiska
- [ ] Implementacja podstawowych funkcji nagrÃ³d
- [ ] Testowanie i debugowanie agentÃ³w

### TydzieÅ„ 5 (10-14.11): Pierwszy trening - podstawowa jazda
- [ ] Uruchomienie pierwszego treningu (algorytm PPO)
- [ ] Monitoring TensorBoard
- [ ] Iteracyjne dostrajanie nagrÃ³d i obserwacji
- [ ] Agent przechodzÄ…cy prosty tor bez wypadania

### TydzieÅ„ 6 (17-21.11): Rozbudowa Å›rodowiska treningowego
- [ ] Projektowanie bardziej skomplikowanego toru (wiÄ™cej zakrÄ™tÃ³w, wzniesienia)
- [ ] Implementacja randomizacji Å›rodowiska (rÃ³Å¼ne kolory, tekstury)
- [ ] Optymalizacja performance'u treningu

### TydzieÅ„ 7 (24-28.11): Optymalizacja funkcji nagrody
- [ ] Zaawansowane nagrody: bonus za prÄ™dkoÅ›Ä‡, kara za zbyt ostre manewry
- [ ] Nagrody za optymalne linie przejazdu (apex points)
- [ ] Testowanie rÃ³Å¼nych wag nagrÃ³d

### TydzieÅ„ 8 (1-5.12): Curriculum Learning
- [ ] Implementacja poziomÃ³w trudnoÅ›ci toru
- [ ] Stopniowe wprowadzanie bardziej skomplikowanych sekcji
- [ ] Automatyczna zmiana trudnoÅ›ci w zaleÅ¼noÅ›ci od postÄ™pÃ³w

### TydzieÅ„ 9 (8-12.12): Przygotowanie do wyÅ›cigÃ³w - Multi-Agent
- [ ] Rozszerzenie sceny o moÅ¼liwoÅ›Ä‡ wielu agentÃ³w jednoczeÅ›nie
- [ ] System detekcji innych pojazdÃ³w (raycasty, sensory)
- [ ] Rozszerzona przestrzeÅ„ obserwacji (pozycje przeciwnikÃ³w)
- [ ] ZarzÄ…dzanie kolizjami miÄ™dzy agentami

### TydzieÅ„ 10 (15-19.12): Self-Play - trening kompetytywny
- [ ] Konfiguracja ML-Agents Self-Play
- [ ] Nagrody za wyprzedzanie przeciwnikÃ³w
- [ ] Kary za zderzenia (ale nie za bliskoÅ›Ä‡)
- [ ] Nagrody za obronÄ™ pozycji

### TydzieÅ„ 11 (7-9.01): Zaawansowane strategie wyÅ›cigowe
- [ ] Fine-tuning nagrÃ³d dla strategii (blokowanie, zajmowanie idealnej linii)
- [ ] Implementacja "Å›wiadomoÅ›ci wyÅ›cigu" (pozycja w stawce)
- [ ] RÃ³Å¼ne style jazdy (agresywny vs defensywny)
- [ ] Long-term planning rewards

### TydzieÅ„ 12 (12-16.01): System wyÅ›cigowy i UI
- [ ] Implementacja systemu startu wyÅ›cigu (grid startowy, countdown)
- [ ] System zliczania okrÄ…Å¼eÅ„
- [ ] Klasyfikacja na Å¼ywo
- [ ] UI: pozycje, czasy, najszybsze okrÄ…Å¼enie
- [ ] System kamer (Å›ledzÄ…ca lidera, swobodna, onboard)

### TydzieÅ„ 13 (19-23.01): Wizualizacja i analiza
- [ ] Dashboard z metrykami treningu
- [ ] Wizualizacja decyzji agenta (debug rays, heatmapy)
- [ ] Statystyki: Å›rednie czasy, Win Rate, liczba wyprzedzeÅ„

### TydzieÅ„ 14 (26-30.01): Prezentacja i dokumentacja
- [ ] Finalna dokumentacja projektu (architektura, wyniki eksperymentÃ³w)
- [ ] Analiza wynikÃ³w (porÃ³wnanie metod, wykres learning curves)
- [ ] Wnioski i moÅ¼liwe rozszerzenia




## Åšrodowisko i zaleÅ¼noÅ›ci
- Unity 6.0 (6000.0.59f2) [LTS] 
- ML-Agents Toolkit (wersja zgodna z Unity 6.0) [link](https://github.com/Unity-Technologies/ml-agents)
- Python 3.10.12 (zgodna z ML-Agents Toolkit)
- TensorBoard
- Numpy, PyTorch



## Rezultaty projektu
- Wytrenowany agent RL zdolny do samodzielnego przejazdu toru w realistycznym Å›rodowisku 3D
- Åšrodowisko wyÅ›cigowe umoÅ¼liwiajÄ…ce symulacje wieloagentowe
- Zestaw metryk i narzÄ™dzi analitycznych do oceny zachowania agentÃ³w i ich strategii w wyÅ›cigach
- Dokumentacja techniczna i raport koÅ„cowy opisujÄ…cy proces uczenia i obserwacje



## Autorzy
- Konrad MaÅ‚ek
- Mateusz Kotarba